
input {
       tcp{
                port => 5045
                type => "tcp"
                ssl_enable =>false
            }
       kafka {
                id => "kafka_plugin_1"
                tags => [“test-kafka-log”]
                topics => ["test"]
                codec => "json"
                type => "add"
                consumer_threads => 3
                bootstrap_servers => "127.0.0.1:9092"
                group_id => "test"
                client_id => "test"
                auto_offset_reset => "earliest"
                    # security_protocol => “SSL”
                    # ssl_key_password => “{ssl_password}”
                    # ssl_keystore_location => “/{keystore-absolute-path}”
                    # ssl_keystore_password => “{keystore_password}”
                    # ssl_truststore_location => “/{truststore-absolute-path}”
                    # ssl_truststore_password => “{truststore_password}”
              }

        }
filter {
        json {
            source => "message"
;             删除字段
;             remove_field => ["message"]
        }
}
filter {
        grok {
                match => {"message" => "(?<logdate>\d{4}-\d{2}-\d{2}\s\d{2}:\d{2}:\d{2}.\d{3})"}
                }
        date {
                match => ["logdate", "yyyy-MM-dd HH:mm:ss.SSS","yyyy-MM-dd HH:mm:ss,SSS"]
                target => "@timestamp"
                }
        mutate {
                remove_field => ["logdate"]
                remove_field => ["tags"]
                }
}
output {
    if "test-kafka-log" in [tags] {
        elasticsearch {
                  hosts => ["127.0.0.1:9200"]
                  index => "test-kafka-log_%{+yyyy.MM.dd}"
;                   user =>
;                   password =>
                  }
        }
        stdout { codec => json }
}

